\documentclass[10pt]{article}
\usepackage{nopageno}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[left=1in, right=1in, top=0.15in, bottom=0.25in]{geometry}
\usepackage{url}
\usepackage{xcolor}
\usepackage{todonotes}
\usepackage[normalem]{ulem}

\newcommand{\suggestM}[2]{{\color{orange} #1}{ \color{red}\sout{#2}}}
\newcommand{\tripleSignature}[3]{
\begin{minipage}[c]{\textwidth}

\vspace{1.5cm}

\makebox[12cm][c]{
\qquad \qquad \qquad \qquad \qquad \makebox[5cm][c] {\hrulefill} \quad \makebox[5cm][c] {\hrulefill} \quad \makebox[5cm][c] {\hrulefill}
}
\makebox[14cm][c]{
\qquad \qquad \qquad #1 \qquad \qquad  #2 \qquad #3 
}
% \vspace{1cm}
\end{minipage}
}


\title{{\normalsize Propuesta de tesis} \\ \textbf{Título}\todo[inline]{Definir}} 
\author{
  \centering
  \begin{tabular}{c c c}
    Alumno & Director & Co-director\\
    Lucas Somacal &  Martin Miguel & Diego Fernández Slezak \\
    lsomacal@gmail.com & mmiguel@dc.uba.ar & dfslezak@dc.uba.ar \\
    LU: 249/16 & & \\
  \end{tabular}
}

\date{}

\begin{document}

% título tentativo de la tesis, introducción o antecedentes en la temática, actividades y metodología a realizar por el tesista, factibilidad de realización en el plazo establecido de común acuerdo entre el director y el tesista y finalmente referencias bibliográficas. La propuesta debe tener como máximo 3 carillas sin contar la bibliografía.

\maketitle

\section*{Introducción}
En los últimos años, nuevas propuestas de arquitecturas de redes neuronales han permitido modelar producciones humanas complejas como el texto escrito. Esto se ha utilizado, por ejemplo, para realizar traducción automática \cite{stahlberg2020neural}, detección de lenguaje de odio \cite{macavaney2019hate} y producción automática de noticias \cite{popel2020news}. Asimismo las mismas técnicas han sido utilizadas para modelar otra producción humana con fines comunicacionales: la música \cite{briot2020deep}. Entre los logros más salientes se encuentran generar un agente que improvisa a la par de un pianista \cite{benetatos2020bachduet}, generar composiciones con estructuras jerárquicas coherentes \cite{Berardinis} y componer automáticamente a partir de un ejemplo musical pero decidiendo el estilo independientemente \cite{payne2019musenet}. 
Estos resultados inspiraron una primera idea de investigación: utilizar técnicas de composición automática para producir posibles continuaciones para la obra inconclusa de Mozart, la misa Requiem K626. Esta idea puede formularse de forma más gneral como la tarea de \emph{transferencia de estilo}, donde se busca tomar un fragmento musical y reinterpretarlo en un estilo distinto al original.

En el área de composición automática de música se persiguen diversos objetivos. Algunos trabajos buscan simplemente poder generar composiciones, normalmente con restricciones de estilo o instrumentación, por ejemplo melodías de RagTime \cite{sun2015ragtime}, melodías y acompaniamientos de corales de Bach \cite{hadjeres2017bach} o secuencias de acordes de estilo Blues \cite{eck2002first}. En otros casos, se busca tener control más detallado sobre las composiciones a partir de información contextual para el modelo. Ejemplos de esto es la composición de patrones de batería a partir de una línea de bajo \cite{makris2017bass} o composición de melodías en estilo pop a partir de una secuencia de acordes \cite{yang2017midinet}. Finalmente, algunos sistemas buscan poder controlar el estilo de la composición, como ser MuseNet \cite{payne2019musenet} o DeepJ \cite{mao2018deepj}.

No obstante, este trabajo se enfoca en la tarea de \emph{transferencia de estilo}, donde se busca reinterpretar un fragmento en un estilo particular. Este problema fue abordado en el ámbito de imágenes, donde es posible modificar fotos para darles el estilo artístico de una artista en particular \cite{gatys2015style} o para modificar atributos particulares (por ejemplo, agregarle anteojos a la foto de una cara) \cite{upchurch2016feature}. Este tipo de transformaciones se han llevado a cabo mediante manipulaciones del espacio latente generado por redes neuronales que aprenden a codificar instancias del dominio de trabajo en espacios de baja dimensionalidad como son las arquitecturas autoencoders \cite{hou2016feature}. Esta tecnica también se ha utilizado para manipular fragmentos musicales. MusicVAE \cite{roberts2019musicvae} permite generar nuevos fragmentos musicales como la interpolación entre otros dos fragmentos. En el trabajo de Guo et al. \cite{guo2020variational}, esta técnica si uiliza para modificar atributos musicales específicos como el nivel de tensión tonal. En este trabajo proponemos basarnos en estas tecnicas para proponer y evaluar un modelo que permita hacer transferencia de estilo para fragmentos musicales.
 
\todo[inline]{Acá falta un último párrafo hablando de la propuesta de metodología de evaluación. Que la tarea de transferencia de estilo no está tan explorada (por lo que se dijo antes) y que se suele evaluar de forma subjetiva mediante evaluaciones de escucha. Como objetivo secundario de este trabajo, proponemos una metodología de evaluación objetiva.}

%\suggestM{}{La propuesta se enmarca en el trabajo doctoral del director, que se enfoca en el desarrollo de modelos computacionales que hagan mímica del proceso de cognición humana al percibir y producir información en el tiempo. En particular es de interés el modelado de cognición musical, por ser un estímulo estructurado que refleja varias capacidades cognitivas de interés, como ser la búsqueda de patrones y la predicción de eventos futuros. La presente propuesta busca interiorizarse con los avances en el modelado de secuencias estructuradas.}

\section*{Actividades y metodologías}
\suggestM{El presente plan de tesis consiste las siguientes tareas. Luego del listado se presenta más detalle respecto de las mismas.}{Se presenta el siguiente detalle de tareas:}

\begin{itemize}
\item Interiorización y aprendizaje de las técnicas utilizadas en el área \suggestM{mediante la lectura de un libro de técnicas de aprendizaje profundo (Goodfellow 2016 \cite{goodfellow2016deep} y un libro de técnicas de composición automática (Briot 2020) \cite{briot2020depp}}{}\cite{briot2020deep, goodfellow2016deep}.
    \item Entendimiento de los datasets existentes de música clásica simbólica  \cite{Cuthbert2010Music21AT}.
    \item Desarrollo de una propuesta de arquitectura para la tarea deseada \suggestM{}{}\cite{guo2020variational, roberts2019musicvae}.
    \item \suggestM{Preparación del pipeline de preprocesamiento}{Preprocesamiento} del dataset para la arquitectura propuesta \suggestM{\cite{Cuthbert2010Music21AT}}{}.
    \item Entrenamiento de modelos en base a la arquitectura y diferentes datasets o preprocesamientos.
    \item Desarrollo de propuestas de evaluación de las producciones realizadas.
    \item Implementación de las evaluaciones.
      \suggestM{\item Escritura de la tesis.}{}
\end{itemize}

\subsection*{Técnicas}
El problema de transferencia de estilos ha tenido su auge en los últimos años con el desarrollo de las nuevas técnicas de aprendizaje profundo. En este sentido, ya que en el problema específico de la música no se han propuesto técnicas específicas, surge la propuesta de basarse en técnicas aplicadas a imágenes \cite{briot2020deep}. En particular, una de estas aproximaciones es con el uso de Autoencoders \cite{goodfellow2016deep} y la consecuente manipulación de los datos en el espacio latente.
\todo[inline]{Esto puede servir para la parte de autoencoders de la intro, acá entraría en más detalle en qué es un autoencoder, porqué tiene sentido el espacio latente}.

\subsection*{Datasets}
\todo[inline]{Acá empezaría mencionando que parte del trabajo es encontrar datasets útiles para la tarea. Que tienen que tener como característica que incluyan distintos estilos musicales y que sean simbólicos. Además es importante tener en cuenta que los modelos de autoencoders no puede manejar cualquier tipo de instrumentación. Después se puede seguir con lo que pusiste.}
Se pretende explorar un conjunto de datasets (MAESTRO, Lakh MIDI, Kunstderfuge, 8notes, MWD, Classical Archive, Nottingham, entre otros). En particular, los más adecuados parecerían ser los provistos por \textit{music21} y \textit{kernScores} dada su libre disponibilidad y por contener ejemplos musicales de distintos estilos.

\subsection*{Arquitectura}
\suggestM{- Esta oración no me gusta tanto. Iría por algo más en la linea de ''Existen dos arquitecturas de autoencodrers aplicadas a música: MusicVAE y la presentada por Guo 2020. - Describir para qué se usaron las dos. Contar la preferencia por Guo.''}{Para encodear los datos y poder manipularlos en el espacio latente son de utilidad arquitecturas que ya han funcionado para otras tareas.} En este sentido, el Proyecto Magenta ha presentado MusicVAE \cite{roberts2019musicvae} o investigadores de la Universidad de Sussex han presentado una arquitectura más chica y por lo tanto, más accesible en cuanto a capacidad de cómputo \cite{guo2020variational}.

\subsection*{Preprocesamiento}
La arquitectura elegida necesitará algún formato particular de los datos. En particular, se necesitan como entrada fragmentos regulares de canciones con exactamente 2 tracks (pistas/voces/instrumentos) cada uno. Sin embargo, en los \textit{datasets} elegidos suele haber canciones con más tracks (un ejemplo clásico es el de los corales de Bach que presentan 4 voces). De este modo, hay que reducir de alguna manera los $n$ tracks de la canción en 2 de manera que uno sea el track con la función del bajo y el otro la de melodía. Para resolver este problema se pretende usar herramientas ya desarrolladas para este fin como el \texttt{midi-miner} de Rui Guo \cite{Guo-reduccion}.

Luego, dado que la red necesita una cantidad fija $n$ de \textit{time steps} (nuestra unidad mínima de tiempo de la canción, que correspondería en principio a una semicorchea), se procederá a dividir cada canción (ya reducida en 2 tracks) en fragmentos de $n$ \textit{time steps}. Sin embargo, esta representación asumiría que toda nota musical dura una cantidad entera de \textit{time steps}. Si bien esta asunción es correcta en la mayoría de los casos, hay situaciones en las cuales no se cumple (ritmos más breves que una semicorchea, como la fusa, o los llamados ``valores irregulares'', divisiones con resultado no entero). Con lo cual, habrá que considerar estos casos suprimiendo o truncando los valores no enteros.
\todo[inline]{Esta parte no se entiende del todo. Acá hay dos ideas: la arquitectura que vamos a usar recibe input de tamaño fijo, por lo que es necesario recortar el las canciones en fragmentos del mismo largo. Por otra parte, también es importante cuantificar el tiempo en unidades regulares. En la mayoría de los casos, esto es fácil de hacer ya que la música en formato simbólico suele anotarse en una grilla discretizada de forma regular. Las excepciones las explicas bien al final del segundo párrafo pero evitaría usar términos musicales.}


\subsection*{Entrenamiento y modelo}
\todo[inline]{No siento que sume mucho esta sección.}
Para entrenar el modelo se puede analizar la convergencia de la función de pérdida en función del \textit{accuracy} de la coincidencia en cada \textit{time step} de un cambio de sonido (ritmo) y de la coincidencia de la altura del sonido (melodía).

Por otro lado, en principio, si bien los modelos de las arquitecturas propuestas son para 4 compases de 4 tiempos de negra cada uno (64 \textit{time steps}), se propone explorar la vialbilidad de modelos que abarquen mayor cantidad de \textit{time steps}.


\subsection*{Evaluación}
Para evaluar la \textit{performance} de los modelos para esta tarea no hay aún nada estandarizado como métrica cuantitativa puesto que la tarea en sí no está muy desarrollada en la actualidad \cite{briot2020deep}. \color{red}\textbf{REVISAR}\color{black}. La evaluación más estándar es cualitativa, mediante encuestas a personas. 

\suggestM{Debido a esto, como parte de este trabajo desarrollaremos métricas de evaluación objetiva de los fragmentos creados por el modelo.}{}
Por lo tanto, se plantean 3 preguntas iniciales \suggestM{para las cuales definiremos métricas de evaluación. Los puntos a evaluar son}{\textit{ad hoc}} (llamando $m$ al fragmento inicial y $m'$ al generado): 
\begin{itemize}
    \item Musicalidad: el fragmento $m'$, ¿suena \textit{musical}?
    \item Estilo: este fragmento, ¿suena más parecido al estilo al que era nuestra intención cambiarse?
    \item Conservación de la canción original: ¿se puede observar que $m'$ está relacionado con $m$? Dicho de otra manera, ¿$m’$ es parecido a $m$?
\end{itemize}

Para la musicalidad proponemos el uso del Information Rate \cite{lattner2018}, métrica basada en la Teoría de la Información \cite{shannon1948} que ha sido usada para este fin en distintos trabajos \cite{lattner2018, WangDubnov2015}. Para el estilo y la conservación de la canción podrían usarse métricas ya existentes de distancia de un punto a una distribución y de plagio.

\section*{Plazos y factibilidad}


\tripleSignature{Alumno (Lucas Somacal)}{Director (Martín Miguel)}{Director (Diego Fernández Slezak)}

% \section{Bibliografía}

\bibliographystyle{unsrt}
{\small
\bibliography{referencias}
}

\end{document}
